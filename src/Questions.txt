/*******************************************************************************
File:             Questions.txt

Author:           Tim Danielsen, danielsen
                  

Completion Date:  12/12/2014

Course:           CS 367, Fall 2014
*******************************************************************************/
Directions: answer the following five (5) questions.  Note: some of the 
questions may require you to know how the LinkedList class is implemented; in 
these cases, you should make a reasonable assumption and clearly indicate your
assumptions in your answer.

1) Suppose you insert an item into your hashtable and then immediately do a 
lookup on that item.  What is the worst-case complexity of your program for 
the lookup in this situation?  Briefly explain your answer.

Answer: If all the items that have been entered so far have the same key value/ get the same result after the hash() method is executed on the key, then the worst-case complexity for lookup would be O(N) because it would be at the end of the linked list at that point in the hashtable, making the program traverse to the end the list to find it.


For questions 2 - 4, you should use the TestHash program as written.

2) In this question you will run MapBenchmark three times using the parameters 
indicated below:
	run1		 randIn1000.txt 100
	run2		 randIn2000.txt 100
	run3 		randIn10000.txt 100

What is the output for each of the runs?  

Answer:
run1:
HashMap: put
--------------------
Min: 0
Max: 6
Mean: 0.200
Std Dev: 0.678

HashMap: get
--------------------
Min: 0
Max: 2
Mean: 0.070
Std Dev: 0.292

HashMap: floorKey
--------------------
Min: 7
Max: 86
Mean: 10.140
Std Dev: 7.785

HashMap: remove
--------------------
Min: 0
Max: 2
Mean: 0.090
Std Dev: 0.319

TreeMap: put
--------------------
Min: 0
Max: 1
Mean: 0.150
Std Dev: 0.357

TreeMap: get
--------------------
Min: 0
Max: 3
Mean: 0.170
Std Dev: 0.448

TreeMap: floorKey
--------------------
Min: 0
Max: 1
Mean: 0.130
Std Dev: 0.336

TreeMap: remove
--------------------
Min: 0
Max: 1
Mean: 0.160
Std Dev: 0.367

run2:
HashMap: put
--------------------
Min: 0
Max: 9
Mean: 0.270
Std Dev: 0.968

HashMap: get
--------------------
Min: 0
Max: 4
Mean: 0.220
Std Dev: 0.540

HashMap: floorKey
--------------------
Min: 31
Max: 127
Mean: 36.450
Std Dev: 9.458

HashMap: remove
--------------------
Min: 0
Max: 1
Mean: 0.180
Std Dev: 0.384

TreeMap: put
--------------------
Min: 0
Max: 1
Mean: 0.170
Std Dev: 0.376

TreeMap: get
--------------------
Min: 0
Max: 1
Mean: 0.150
Std Dev: 0.357

TreeMap: floorKey
--------------------
Min: 0
Max: 1
Mean: 0.190
Std Dev: 0.392

TreeMap: remove
--------------------
Min: 0
Max: 3
Mean: 0.250
Std Dev: 0.497

run3:
HashMap: put
--------------------
Min: 0
Max: 19
Mean: 1.010
Std Dev: 2.017

HashMap: get
--------------------
Min: 0
Max: 5
Mean: 0.720
Std Dev: 0.826

HashMap: floorKey
--------------------
Min: 866
Max: 1715
Mean: 1092.590
Std Dev: 143.201

HashMap: remove
--------------------
Min: 0
Max: 5
Mean: 0.660
Std Dev: 0.777

TreeMap: put
--------------------
Min: 0
Max: 3
Mean: 0.620
Std Dev: 0.704

TreeMap: get
--------------------
Min: 0
Max: 2
Mean: 0.700
Std Dev: 0.608

TreeMap: floorKey
--------------------
Min: 0
Max: 3
Mean: 0.770
Std Dev: 0.705

TreeMap: remove
--------------------
Min: 0
Max: 2
Mean: 0.600
Std Dev: 0.632


3) In this question you will again run TestHash three times, this time using the 
parameters:
	run4		 badIn1000.txt 100
	run5		 badIn2000.txt 100
	run6 		badIn10000.txt 100

What is the output for each of the runs?  

Answer:
run4:
HashMap: put
--------------------
Min: 7
Max: 12
Mean: 8.230
Std Dev: 0.947

HashMap: get
--------------------
Min: 0
Max: 15
Mean: 12.370
Std Dev: 2.038

HashMap: floorKey
--------------------
Min: 10
Max: 57
Mean: 12.550
Std Dev: 4.651

HashMap: remove
--------------------
Min: 0
Max: 2
Mean: 0.100
Std Dev: 0.332

TreeMap: put
--------------------
Min: 0
Max: 1
Mean: 0.050
Std Dev: 0.218

TreeMap: get
--------------------
Min: 0
Max: 1
Mean: 0.020
Std Dev: 0.140

TreeMap: floorKey
--------------------
Min: 0
Max: 2
Mean: 0.080
Std Dev: 0.306

TreeMap: remove
--------------------
Min: 0
Max: 1
Mean: 0.070
Std Dev: 0.255

run5:
HashMap: put
--------------------
Min: 9
Max: 76
Mean: 69.030
Std Dev: 7.043

HashMap: get
--------------------
Min: 2
Max: 119
Mean: 105.140
Std Dev: 14.894

HashMap: floorKey
--------------------
Min: 44
Max: 182
Mean: 155.500
Std Dev: 14.028

HashMap: remove
--------------------
Min: 0
Max: 4
Mean: 0.220
Std Dev: 0.540

TreeMap: put
--------------------
Min: 0
Max: 1
Mean: 0.160
Std Dev: 0.367

TreeMap: get
--------------------
Min: 0
Max: 1
Mean: 0.230
Std Dev: 0.421

TreeMap: floorKey
--------------------
Min: 0
Max: 1
Mean: 0.200
Std Dev: 0.400

TreeMap: remove
--------------------
Min: 0
Max: 1
Mean: 0.200
Std Dev: 0.400

run6:
HashMap: put
--------------------
Min: 234
Max: 22651
Mean: 21193.650
Std Dev: 2123.899

HashMap: get
--------------------
Min: 2271
Max: 48101
Mean: 33394.000
Std Dev: 3738.418

HashMap: floorKey
--------------------
Min: 9836
Max: 82561
Mean: 62272.430
Std Dev: 6003.334

HashMap: remove
--------------------
Min: 0
Max: 1946
Mean: 20.430
Std Dev: 193.528

TreeMap: put
--------------------
Min: 0
Max: 3
Mean: 0.560
Std Dev: 0.622

TreeMap: get
--------------------
Min: 0
Max: 2
Mean: 0.560
Std Dev: 0.554

TreeMap: floorKey
--------------------
Min: 0
Max: 3
Mean: 0.540
Std Dev: 0.670

TreeMap: remove
--------------------
Min: 0
Max: 4
Mean: 0.620
Std Dev: 0.660

4) Briefly analyze your results from questions 2 and 3. Consider the 
following aspects:
	- underlying data structure
	- the number of inputs
	- the input file
How do these aspects influence the statistics? How do the table statistics 
affect the performance (times)? 

Answer:
The number of inputs have almost no effect on SimpleTreeMap, but it significantly increases the runtime for SimpleHashMap. SimpleHashMap takes significantly longer for bad input files compared to SimpleHashMap. The table statistics donâ€™t have any affect on the performance because the only thing being timed is the operation itself, nothing else.

5) Using the above data, give the complexity of each SimpleMapADT method for 
SimpleTreeMap and SimpleHashMap.  Justify your answer with your run results.

Answer:
SimpleTreeMap:
put: O(logN) because the run time slowly goes up as the sample size increases.
get: O(logN) because the run time slowly goes up as the sample size increases.
floorKey: O(logN) because the run time slowly goes up as the sample size increases.
remove: O(logN) because the run time slowly goes up as the sample size increases.
SimpleHashMap:
put: O(N) because when the array has to expand, the expansion is O(N)
get: O(1) because the run time is more or less the same and only increases with more collisions.
floorKey: O(N) because has to do a O(1) operation N times.
remove: O(1) because the run time is more or less the same and only increases with more collisions 


 
